# -*- coding: utf-8 -*-
"""WeatherForecast.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BddQDCoNG2gDbheBcCiAiBua6eCHouQV

# Only with gooogle colab
from google.colab import drive
drive.mount("/content/drive")

# CLASS PREPROCESSING DATASET
"""

# Standard libraries
import time
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import pickle
import seaborn as sns
import matplotlib.pyplot as plt
from zipfile import ZipFile

class PreprocessDataset:
    """
    Class object to clean the weather.csv dataset.

    Parameters
    ____________________________________________________________________________
    filepath_load: str (filepath of the file to be loaded)
    filepath_save: str (filepath of the file to be saved)
    cols_to_drop: list of str (columns to drop from the dataset)
    cols_idx_groupby: list of str (cols used to groupby)
    """

    def __init__(self, filepath_load, filepath_save, cols_to_drop, cols_idx_groupby, zipped=False):
        self.filepath_load = filepath_load
        self.filepath_save = filepath_save
        self.cols_to_drop = cols_to_drop
        self.cols_idx_groupby = cols_idx_groupby
        self.zipped=zipped
      
    def __load_file_zippped(self):
        start_time = time.time()
        try:
            print(os.path.exists(self.filepath_load))
            zf = zipfile.ZipFile(self.filepath_load, 'r')
            df = pd.read_csv(zf, low_memory=False)
            return df
        except:
            print("Invalid file")
            return None
       
    def __load_file(self):
        start_time = time.time()
        with open(self.filepath_load, 'rb') as handle:
            self.dataset_raw = pickle.load(handle)
        total_time = - start_time + time.time()
        print(f"File has been loaded in {total_time} seconds.")

    def __load_file_dataframe(self):
        if self.filepath_load.endswith("pkl"):
            df = pd.read_pickle(self.filepath_load)
        else:
            start_time = time.time()
            df = pd.read_csv(self.filepath_load, low_memory=False)
            total_time = - start_time + time.time()
            print(f"File has been loaded in {total_time} seconds.")
        return df

    def __clean_dataframe(self, df):

        start_time = time.time()

        # Drop col with std = 0 and features not relevant to prediction weather
        # Convert the header names to all uppercase
        df.columns = df.columns.str.upper()
        cleaned_df = df.copy()   
        cleaned_df["TIME_SESSION"] = cleaned_df["M_SESSION_DURATION"] - cleaned_df["M_SESSION_TIME_LEFT"]
        cleaned_df.drop(self.cols_to_drop, axis=1, inplace=True) 
        

        # Groupby session link identifier
        list_session_df = self.__groupby_dataframe(cleaned_df)

        # Drop session with number 13 and 0: time trial, unknown
        for i, dataframe in enumerate(list_session_df):
            session_type = list_session_df[0]["M_SESSION_TYPE"].value_counts().index[0]
        if (session_type == 13) or (session_type == 0):
            del list_session_df[i]

        # Drop rows with NaN
        for i, dataframe in enumerate(list_session_df):
            dataframe.drop_duplicates(keep="first", inplace=True)
            dataframe.dropna(axis=0, inplace=True)

        # Drop rows with all zeros
        for i, dataframe in enumerate(list_session_df):
            list_session_df[i] = dataframe[dataframe['M_WEATHER_FORECAST_SAMPLES_M_SESSION_TYPE'] != 0]

        # Keep only dataframe where M_SESSION_TYPE == M_WEATHER_FORECAST_SAMPLES_M_SESSION_TYPE
        for i, dataframe in enumerate(list_session_df):
            list_session_df[i] = list_session_df[i][list_session_df[i]["M_SESSION_TYPE"] == \
                                           list_session_df[i]["M_WEATHER_FORECAST_SAMPLES_M_SESSION_TYPE"]].copy()
            list_session_df[i] = list_session_df[i][(list_session_df[i]["M_TIME_OFFSET"] != 45)  &
                                           (list_session_df[i]["M_TIME_OFFSET"] != 120) & 
                                           (list_session_df[i]["M_TIME_OFFSET"] != 90)] 

        # Delete cyclic offset for the same timestamp
        for i, dataframe in enumerate(list_session_df):
           list_session_df[i] = self.__drop_cyclic_offset(dataframe)
            
        print(f"Preprocessing is over, time taken: {- start_time + time.time()}")
        return list_session_df
    
 
    def __groupby_dataframe(self, cleaned_df):
        grouped_df = cleaned_df.groupby(self.cols_idx_groupby) # per sessionID, player car index
        list_session_df = []
        for key,item in grouped_df:
            list_session_df.append(grouped_df.get_group(key))
        return list_session_df

    def __drop_cyclic_offset(self, dataframe):

        if dataframe.shape[0] != 0:
           list_temp_df = []
           cycle_offset = np.unique(dataframe["M_TIME_OFFSET"])
           for idx, timestamp in enumerate(np.unique(dataframe["M_SESSION_TIME_LEFT"])):
               temp_df = dataframe[dataframe["M_SESSION_TIME_LEFT"]==timestamp]
               sorted_temp = temp_df.sort_values(by="M_TIME_OFFSET")
               list_temp_df.append(sorted_temp.drop_duplicates(["M_TIME_OFFSET"]))
               print("Finish filtering cyclic data")
           return pd.concat(list_temp_df)
        else:
           return dataframe

    def __save_file(self, list_session_df):
        start_time = time.time()
        with open(self.filepath_save, 'wb') as handle:
            pickle.dump(list_session_df, handle)
        total_time = - start_time + time.time()
        print(f"File has been saved in {total_time} seconds.")

    def run_proprocessing(self):
        if self.zipped == True:
            dataframe_raw = self.__load_file_zippped()
        else: 
            dataframe_raw = self.__load_file_dataframe()
        list_session_df = self.__clean_dataframe(dataframe_raw)
        answer_save = int(input("Do you want to save the file? 1: yes, 0: no"))
        if answer_save == 1:
            self.__save_file(list_session_df)
            return list_session_df
        else:
            print("File not saved")
            return list_session_df


    def unix_to_timestamp(self, list_session_df):
        for i, dataframe in enumerate(list_session_df):
            try:
                list_session_df[i]["TIMESTAMP"] = \
                list_session_df[i]["TIMESTAMP"].apply(lambda x: pd.to_datetime(x).value / 1e9)
            except:
                print(i)
        return list_session_df


    def timestamp_to_unix(self, list_session_df):
        for i, dataframe in enumerate(list_session_df):
            try:
                list_session_df[i]["TIMESTAMP"] = \
                list_session_df[i]["TIMESTAMP"].apply(lambda x: pd.to_datetime(x, unit='s'))
            except:
                print(i)
        return list_session_df

